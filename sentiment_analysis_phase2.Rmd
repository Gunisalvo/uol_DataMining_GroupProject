---
title: "Data Mining Group project: Ali, Li, Rodrigo"
output: html_notebook
---
## You may need to install this, so uncomment the next 2 lines and run once.
library(devtools)
install_github("jeroen/mongolite")
install.packages('rvest')
install.packages('xml2')
install.packages('tidytext')
install.packages('tidyverse')
install_github("ggrothendieck/sqldf")
library(mongolite)
library(tidyverse)      # data manipulation & plotting
library(stringr)        # text cleaning and regular expressions
library(tidytext)       # provides additional text mining functions
library(magrittr)
library(sqldf)

## Connect to the DB, please replace username and password by the ones shared on the forum
con <- mongo("reviews", url = "mongodb://datamining:datamining@ds113445.mlab.com:13445/heroku_8tv2vqr4")

# Load all reviews
reviews <- con$find()

word_count <- tibble()

for(i in 1:500){
  r <- reviews[i,]
  clean <- tibble(chapter=i, text=r$reviewText) %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words)
    
  clean$score <- r$overall

  word_count <- rbind(word_count, clean)
}

word_count_breakdown <- word_count %>% group_by(chapter, word, score) %>% count(word)
colnames(word_count_breakdown)[colnames(word_count_breakdown) == 'n'] <- 'word_count'

score_breakdown <- word_count_breakdown %>%
  right_join(get_sentiments("nrc")) %>%
  filter(!is.na(sentiment)) %>%
  count(sentiment, sort = TRUE)
colnames(score_breakdown)[colnames(score_breakdown) == 'n'] <- 'word_count'

score_breakdown_clean <- sqldf("select chapter, sentiment, score, sum(word_count) as 'count' from score_breakdown where chapter <> 'NA' group by chapter, sentiment, score")

score_breakdown_clean

sentiment_list <- (sqldf("select distinct(sentiment) from score_breakdown_clean where chapter <> 'NA' group by sentiment"))$sentiment

relevant_attributes <- c(c("review", "score"), sentiment_list)

print(relevant_attributes)

scores <- as.data.frame(
  setNames(replicate(length(relevant_attributes), integer()),relevant_attributes[1:length(relevant_attributes)])
)
names(scores) <- relevant_attributes

str(scores)

for(i in sqldf("select distinct(chapter) as 'chapter' from score_breakdown_clean")$chapter){
  s <- list()
  s$review <- i
  s$score <- sqldf(sprintf("select distinct(score) as 'score' from score_breakdown_clean where chapter = '%s' ", i))$score
  
  for(sent in sentiment_list){
    value <- sqldf(sprintf("select distinct(count) as 'count' from score_breakdown_clean where chapter = '%s' and sentiment = '%s' ", i, sent))$count
    if(length(value) == 0){
      s[[sent]] <- 0
    }else{
      s[[sent]] <- value
    }
  }
  scores <- rbind(scores, data.frame(s))
}

set.seed(123)

train_sample <- sample(nrow(scores), nrow(scores) - (nrow(scores) %/% 10))

scores.train_scores <- scores[train_sample,]$score
scores.train <- scores[train_sample,][-1:-2]
scores.train_pn <- scores[train_sample,][9] - scores[train_sample,][8]
scores.test_scores <- scores[-train_sample,]$score
scores.test <- scores[-train_sample,][-1:-2]
scores.test_pn <- scores[-train_sample,][9] - scores[-train_sample,][9]

library(class)

scores.eucledian <- knn(train=scores.train, test=scores.test, cl=scores.train_scores, k=5)

library(gmodels)

CrossTable(x=scores.test_scores, y=scores.eucledian, prop.chisq=FALSE)

scatter.smooth(x=scores.train_scores, y=scores.train_pn$positive, xlab = "score", ylab = "sentiment" ,main="Sentiment ~ Score")

install.packages("KernelKnn")
library(KernelKnn)

scores.cosine <- KernelKnn(scores.train, TEST_data = scores.test, y = scores.train_scores, k = 10, method = 'canberra', weights_function = 'cosine', Levels = unique(scores.train_scores), regression=F)

scores.cosine_result <- list()

for(i in 1:nrow(scores.cosine)){
  x <- NA
  if(!is.nan(max(scores.cosine[i,]))){
    x <- which(scores.cosine[i,]==max(scores.cosine[i,]))
  }
  scores.cosine_result <- rbind(scores.cosine_result, x)
}

CrossTable(x=scores.test_scores, y=unlist(scores.cosine_result), prop.chisq=FALSE)